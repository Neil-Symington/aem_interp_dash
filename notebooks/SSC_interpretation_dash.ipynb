{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import netCDF4\n",
    "import sys, os\n",
    "sys.path.append(\"../scripts\")\n",
    "\n",
    "import spatial_functions\n",
    "import aem_utils\n",
    "import netcdf_utils\n",
    "import modelling_utils\n",
    "import plotting_functions as plots\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "# Dash dependencies\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the LCI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual inversoin data are stored on disk as netcdf files. NetCDF is an efficient format for storing \n",
    "# self-describing containerised data. \n",
    "# The implementation of netcdf for AEM line data was done by Alex Ip using his geophys_utils package.\n",
    "# https://github.com/GeoscienceAustralia/geophys_utils/tree/master/geophys_utils\n",
    "\n",
    "\n",
    "root = r\"C:\\Users\\symin\\OneDrive\\Documents\\GA\\AEM\\LCI\"\n",
    "\n",
    "# Define path to the netcdf file\n",
    "infile = os.path.join(root, \"Injune_lci_MGA55.nc\")\n",
    "\n",
    "# Create an instance\n",
    "lci = aem_utils.AEM_inversion(name = 'Laterally Contrained Inversion (LCI)',\n",
    "                              inversion_type = 'deterministic',\n",
    "                              netcdf_dataset = netCDF4.Dataset(infile))\n",
    "\n",
    "# As these inversions have already been gridded we will add these raster datasets to the instance using the\n",
    "# load_lci_layer_grid() function. This function belongs to the AEM_inversion class.\n",
    "\n",
    "# Directory in which the grids are located\n",
    "infile = os.path.join(root, \"grids\\\\Injune_layer_grids.p\")\n",
    "\n",
    "# Run function\n",
    "lci.load_lci_layer_grids_from_pickle(infile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the garjmcmctdem inversion and probe the results using the same syntax as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to netcdf file\n",
    "infile = r\"C:\\Users\\symin\\OneDrive\\Documents\\GA\\AEM\\rjmcmc\\Injune_petrel_rjmcmc_pmaps.nc\"\n",
    "\n",
    "\n",
    "# Create instance\n",
    "rj = aem_utils.AEM_inversion(name = 'GARJMCMCTDEM',\n",
    "                             inversion_type = 'stochastic',\n",
    "                             netcdf_dataset = netCDF4.Dataset(infile))\n",
    "\n",
    "##TODO add nsamples as a scalar variable\n",
    "rj.nsamples = np.sum(rj.data['log10conductivity_histogram'][0], axis = 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the lines we can grid the lci conductivity data onto vertical grids (known as sections)\n",
    "# this is the easiest way to visualise the AEM conuctivity in 2-dimensions\n",
    "\n",
    "# Assign the lci variables to grid\n",
    "grid_vars = ['conductivity', 'data_residual', 'depth_of_investigation']\n",
    "\n",
    "\n",
    "# Define the resolution of the sections\n",
    "xres, yres = 40., 5.\n",
    "\n",
    "# We will use the lines from the rj\n",
    "\n",
    "lines = [200101, 200401, 200501, 200801,\n",
    "         200901, 201001, 201101, 201201, 201301, 201401, 201501,\n",
    "         201601, 201701, 201801, 201901, 202001, 202101, 202201,\n",
    "         202301, 202401, 202501, 202601, 202701, 202801, 912011]\n",
    "\n",
    "# Define the output directory if saving the grids as hdf plots\n",
    "\n",
    "hdf5_dir = r\"C:\\temp\\Injune_hdf5\"\n",
    "\n",
    "# if the directory doesn't exist, then create it\n",
    "if not os.path.exists(hdf5_dir):\n",
    "    os.mkdir(hdf5_dir)  \n",
    "\n",
    "# Gridding takes a few minutes so I pre-gridded them for you. The lci.grid_sections()\n",
    "# function below will do the gridding for you. Instead we will use the load_sectoin_from_file()\n",
    "# function, which loads hdf5 files produced using the grid_sections() function\n",
    "\n",
    "\n",
    "#lci.grid_sections(variables = grid_vars, lines = lines, xres = xres, yres = yres,\n",
    "#                  return_interpolated = True, save_hdf5 = True, hdf5_dir = hdf5_dir)\n",
    "\n",
    "lci.load_sections_from_file(hdf5_dir, grid_vars, lines = lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid the rj sections\n",
    "\n",
    "# Assign the lci variables to grid\n",
    "grid_vars = ['conductivity_p10', 'conductivity_p50', 'conductivity_p90', 'interface_depth_histogram',\n",
    "             'misfit_lowest', 'misfit_average']\n",
    "\n",
    "# Define the resolution of the sections\n",
    "xres, yres = 50., 2.\n",
    "\n",
    "# We will use the lines from the rj\n",
    "\n",
    "lines = [200101, 200401, 200501, 200801,\n",
    "         200901, 201001, 201101, 201201, 201301, 201401, 201501,\n",
    "         201601, 201701, 201801, 201901, 202001, 202101, 202201,\n",
    "         202301, 202401, 202501, 202601, 202701, 202801, 912011]\n",
    "\n",
    "# Define the output directory if saving the grids as hdf plots\n",
    "\n",
    "hdf5_dir = r\"C:\\Temp\\SSC_hdf5_rj\"\n",
    "\n",
    "# if the directory doesn't exist, then create it\n",
    "if not os.path.exists(hdf5_dir):\n",
    "    os.mkdir(hdf5_dir)  \n",
    "\n",
    "rj.grid_sections(variables = grid_vars, lines = lines, xres = xres, yres = yres,\n",
    "                  return_interpolated = True, save_hdf5 = True, hdf5_dir = hdf5_dir)\n",
    "\n",
    "#rj.load_sections_from_file(hdf5_dir, grid_vars, lines = lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Create polylines\n",
    "lci.create_flightline_polylines()\n",
    "\n",
    "gdf_lines = gpd.GeoDataFrame(data = {'lineNumber': lci.flight_lines.keys(),\n",
    "                                     'geometry': lci.flight_lines.values()},#[x.wkt for x in lci.flight_lines.values()]},\n",
    "                             geometry= 'geometry',\n",
    "                             crs = 'EPSG:28353')\n",
    "gdf_lines = gdf_lines[np.isin(gdf_lines['lineNumber'], rj.data['line'][:])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Using this gridding we find the distance along the line for each site\n",
    "# Iterate through the lines\n",
    "rj.distance_along_line = {}\n",
    "\n",
    "for lin in lines:\n",
    "    # Get a line mask\n",
    "    line_mask = netcdf_utils.get_lookup_mask(lin, rj.data)\n",
    "    # get the coordinates\n",
    "    line_coords = rj.coords[line_mask]\n",
    "\n",
    "    dists = spatial_functions.xy_2_var(lci.section_data[lin],\n",
    "                                      line_coords,\n",
    "                                      'grid_distances')\n",
    "    # Add a dictionary with the point index distance along the line to our inversion instance\n",
    "    rj.distance_along_line[lin] = pd.DataFrame(data = {\"point_index\": np.where(line_mask)[0],\n",
    "                                                       \"distance_along_line\": dists,\n",
    "                                                       'fiducial': rj.data['fiducial'][line_mask]}\n",
    "                                               ).set_index('point_index')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Setup your model\n",
    "\n",
    "Now we want to create a model boundary object for our interpreted surface. The easiest way to manage this is to have a separate instance the module boundary for every interface. This will allow us to produce eggs ready output files as we go.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an modelled boundary instance\n",
    "\n",
    "headings = [\"fiducial\", \"inversion_name\",'X', 'Y', 'ELEVATION', \"DEM\", \"DEPTH\", \"UNCERTAINTY\", \"Type\",\n",
    "            \"BoundaryNm\", \"BoundConf\", \"BasisOfInt\", \"OvrConf\", \"OvrStrtUnt\", \"OvrStrtCod\", \"UndStrtUnt\",\n",
    "           \"UndStrtCod\", \"WithinType\", \"WithinStrt\", \"WithinStNo\", \"WithinConf\", \"InterpRef\",\n",
    "            \"Comment\", \"SURVEY_LINE\", \"Operator\"]\n",
    "\n",
    "interp_file = r\"C:\\temp\\top_Precipice_interpreted_points.csv\"\n",
    "\n",
    "EP_surface = modelling_utils.modelled_boundary(name = 'Top=Precipice interface',\n",
    "                                               outfile_path = interp_file,\n",
    "                                               interpreted_point_headings = headings)\n",
    "#MP_surface.interpreted_points = pd.read_csv(interp_file)\n",
    "# Define your surface\n",
    "surface = EP_surface\n",
    "\n",
    "# Assign attributes base on what you want to be\n",
    "# entered into the eggs database\n",
    "surface.Type = \"INTRA_Paleozoic\"\n",
    "surface.OvrStrtUnt = \"Evergreen Formation\"\n",
    "surface.OvrStrtCod = 6416\n",
    "surface.UndStrtUnt = \"Precipice Sandstone\"\n",
    "surface.UndStrtCod = 15540\n",
    "surface.Inversion_name = \"\"\n",
    "surface.BoundConf = \"M\"\n",
    "surface.BasisOfInt = \"IAEM\"\n",
    "surface.OvrConf = \"M\"\n",
    "surface.InterpRef = \"\"\n",
    "surface.Comment = \"\"\n",
    "surface.Operator = \"John Fish\"\n",
    "surface.WithinType = \"\"\n",
    "surface.WithinStrt = \"\"\n",
    "surface.WithinStNo = \"\"\n",
    "surface.WithinConf = \"\"\n",
    "\n",
    "line_options = []\n",
    "\n",
    "for l in lines:\n",
    "     line_options.append({'label': str(l), 'value': l})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def subset_df_by_line(df_, line, line_col = 'SURVEY_LINE'):\n",
    "    mask = df_[line_col] == line\n",
    "    return df_[mask]\n",
    "\n",
    "# section functions\n",
    "def xy2fid(x,y, dataset):\n",
    "    dist, ind = spatial_functions.nearest_neighbours([x, y],\n",
    "                                                     dataset.coords,\n",
    "                                                     max_distance = 100.)\n",
    "    return dataset.data['fiducial'][ind][0]\n",
    "\n",
    "def interp2scatter(line, gridded_data, interpreted_points, easting_col = 'X',\n",
    "                   northing_col = 'Y', elevation_col = 'ELEVATION',\n",
    "                   line_col = 'SURVEY_LINE'):\n",
    "\n",
    "    utm_coords = np.column_stack((gridded_data[line]['easting'],\n",
    "                                  gridded_data[line]['northing']))\n",
    "\n",
    "    df_ = subset_df_by_line(interpreted_points, line, line_col = line_col)\n",
    "\n",
    "    dist, inds = spatial_functions.nearest_neighbours(df_[[easting_col,northing_col]].values,\n",
    "                                                      utm_coords, max_distance=100.)\n",
    "\n",
    "    grid_dists = gridded_data[line]['grid_distances'][inds]\n",
    "    elevs = df_[elevation_col].values\n",
    "    fids = df_['fiducial'].values\n",
    "\n",
    "    return  grid_dists, elevs, fids\n",
    "\n",
    "def layer_point_prob_plot(section_data, line):\n",
    "    # Flatten into x,z, probability\n",
    "    c = section_data[line]['interface_depth_histogram'].flatten()\n",
    "\n",
    "\n",
    "    x = np.tile(section_data[line]['grid_distances'],\n",
    "                len(section_data[line]['grid_elevations']))\n",
    "    y = np.repeat(section_data[line]['grid_elevations'],\n",
    "                  len(section_data[line]['grid_distances']))\n",
    "\n",
    "    x = x[np.isfinite(c)]\n",
    "    y = y[np.isfinite(c)]\n",
    "    c = c[np.isfinite(c)]\n",
    "\n",
    "    # convert to probability\n",
    "    c = c/np.max(c)\n",
    "\n",
    "    return x, y, c\n",
    "\n",
    "def dash_section(line, df_interp, colours, section_kwargs):\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=2, cols = 1, shared_xaxes=True,\n",
    "                        vertical_spacing=0.05,\n",
    "                        row_heights=[0.2, 0.8])\n",
    "\n",
    "    # plot the data residual\n",
    "    if section_kwargs['section_plot'] == \"lci\":\n",
    "        section_data = lci.section_data\n",
    "        fig.add_trace(go.Scatter(x = section_data[line]['grid_distances'],\n",
    "                                 y = section_data[line]['data_residual'],\n",
    "                                 line=dict(color='black', width=3),\n",
    "                                 showlegend = False, hoverinfo = None),\n",
    "                       row = 1, col = 1,)\n",
    "    else:\n",
    "        section_data = rj.section_data\n",
    "        fig.add_trace(go.Scatter(x = section_data[line]['grid_distances'],\n",
    "                                 y = np.log10(section_data[line]['misfit_lowest']),\n",
    "                                 line=dict(color='black', width=3),\n",
    "                                 showlegend = False, hoverinfo = None),\n",
    "                       row = 1, col = 1,)\n",
    "\n",
    "    # Create the grid\n",
    "    if section_kwargs['section_plot'] == \"lci\":\n",
    "        fig.add_trace(go.Heatmap(z = np.log10(section_data[line]['conductivity']),\n",
    "                        zmin = np.log10(section_kwargs['vmin']),\n",
    "                        zmax = np.log10(section_kwargs['vmax']),\n",
    "                        x = section_data[line]['grid_distances'],\n",
    "                        y = section_data[line]['grid_elevations'],\n",
    "                        colorscale =section_kwargs['cmap'],\n",
    "                        #hoverlabel=dict(x=\"Distance along line\", y=\"elevation (mAHD)\"),\n",
    "                        ),\n",
    "                      row = 2, col = 1,\n",
    "        )\n",
    "    elif section_kwargs['section_plot'] == \"rj-p50\":\n",
    "        fig.add_trace(go.Heatmap(z = np.log10(section_data[line]['conductivity_p50']),\n",
    "                        zmin = np.log10(section_kwargs['vmin']),\n",
    "                        zmax = np.log10(section_kwargs['vmax']),\n",
    "                        x = section_data[line]['grid_distances'],\n",
    "                        y = section_data[line]['grid_elevations'],\n",
    "                        colorscale =section_kwargs['cmap'],\n",
    "                        #hoverlabel=dict(x=\"Distance along line\", y=\"elevtion (mAHD)\"),\n",
    "                        ),\n",
    "                      row = 2, col = 1,\n",
    "        )\n",
    "\n",
    "    elif section_kwargs['section_plot'] == 'rj-conf':\n",
    "\n",
    "        confidence = plots.percentiles2pnci(section_data[line]['conductivity_p10'],\n",
    "                                            section_data[line]['conductivity_p90'],\n",
    "                                            upper_threshold = 0.99,\n",
    "                                            lower_threshold = 0.01)\n",
    "\n",
    "        fig.add_trace(go.Heatmap(z = confidence,\n",
    "                        zmin = 0.1,\n",
    "                        zmax = 0.9,\n",
    "                        x = section_data[line]['grid_distances'],\n",
    "                        y = section_data[line]['grid_elevations'],\n",
    "                        colorscale =\"YlGn\"\n",
    "                        #hoverlabel=dict(x=\"Distance along line\", y=\"elevation (mAHD)\"),\n",
    "                        ),\n",
    "                      row = 2, col = 1,\n",
    "        )\n",
    "\n",
    "    elif section_kwargs['section_plot'] == \"rj-lpp\":\n",
    "\n",
    "        fig.add_trace(go.Heatmap(z = section_data[line]['interface_depth_histogram']/rj.nsamples,\n",
    "                        zmin = 0.01,\n",
    "                        zmax = 0.7,\n",
    "                        x = section_data[line]['grid_distances'],\n",
    "                        y = section_data[line]['grid_elevations'],\n",
    "                        colorscale =\"greys\",\n",
    "                        #hoverlabel=dict(x=\"Distance along line\", y=\"elevation (mAHD)\"),\n",
    "                        ),\n",
    "                      row = 2, col = 1,\n",
    "        )\n",
    "\n",
    "    # Add the elevation\n",
    "    fig.add_trace(go.Scatter(x = section_data[line]['grid_distances'],\n",
    "                             y = section_data[line]['elevation'],\n",
    "                             line=dict(color='black', width=3),\n",
    "                             showlegend = False, hoverinfo = None),\n",
    "                  row = 2, col = 1,)\n",
    "\n",
    "    # Now we add the rjmcmc sites to the section\n",
    "\n",
    "    df_rj_sites = rj.distance_along_line[line]\n",
    "\n",
    "    labels = [\"fiducial = \" + str(x) for x in df_rj_sites['fiducial']]\n",
    "\n",
    "    fig.add_trace(go.Scatter(x = df_rj_sites['distance_along_line'].values,\n",
    "                    y = 20. +np.max(section_data[line]['elevation'])*np.ones(shape = len(df_rj_sites),\n",
    "                                                                        dtype = np.float),\n",
    "                    mode = 'markers',\n",
    "                    hovertext = labels),\n",
    "                  row = 2, col = 1)\n",
    "\n",
    "    if len(df_interp) > 1:\n",
    "        if np.logical_or(section_kwargs['section_plot'] == \"rj-p50\",\n",
    "                         section_kwargs['section_plot'] == \"lci\"):\n",
    "            # Get the ticks\n",
    "            tickvals = np.linspace(np.log10(section_kwargs['vmin']),\n",
    "                                    np.log10(section_kwargs['vmax']),\n",
    "                                    5)\n",
    "\n",
    "            ticktext = [str(np.round(x,3)) for x in 10**tickvals]\n",
    "\n",
    "            fig.update_layout(coloraxis_colorbar=dict(\n",
    "            title=\"conductivity\",\n",
    "            tickvals=tickvals,\n",
    "            ticktext=ticktext,\n",
    "            ))\n",
    "\n",
    "        interpx, interpz, fids = interp2scatter(line, section_data, df_interp)\n",
    "\n",
    "        if len(interpx) > 0:\n",
    "            labels = [\"fiducial = \" + str(x) for x in fids]\n",
    "\n",
    "            fig.add_trace(go.Scatter(x = interpx,\n",
    "                            y = interpz,\n",
    "                            mode = 'markers',\n",
    "                            hovertext = labels,\n",
    "                            marker = {\"color\": colours}),\n",
    "                          row = 2, col = 1\n",
    "                          )\n",
    "\n",
    "    # Reverse y-axis\n",
    "    fig.update_yaxes(autorange=True)\n",
    "\n",
    "    return fig\n",
    "\n",
    "def dash_pmap_plot(point_index):\n",
    "    # Extract the data from the netcdf data\n",
    "    D = netcdf_utils.extract_rj_sounding(rj, lci,\n",
    "                                         point_index)\n",
    "    pmap = D['conductivity_pdf']\n",
    "    x1,x2,y1,y2 = D['conductivity_extent']\n",
    "    n_depth_cells, n_cond_cells  = pmap.shape\n",
    "\n",
    "    x = np.linspace(x1,x2, n_cond_cells)\n",
    "    y = np.linspace(y2,y1, n_depth_cells)\n",
    "\n",
    "    fig = px.imshow(img = pmap,\n",
    "                    x = x, y = y,\n",
    "                    zmin = 0,\n",
    "                    zmax = np.max(pmap),\n",
    "                    aspect = 'auto',\n",
    "                    color_continuous_scale = 'plasma')\n",
    "    #  PLot the median, and percentile plots\n",
    "    fig.add_trace(go.Scatter(x = np.log10(D['cond_p10']),\n",
    "                             y = D['depth_cells'],\n",
    "                             mode = 'lines',\n",
    "                             line = {\"color\": 'black',\n",
    "                                     \"width\": 2.},\n",
    "                             name = \"p10 conductivity\"))\n",
    "    fig.add_trace(go.Scatter(x = np.log10(D['cond_p90']),\n",
    "                             y = D['depth_cells'],\n",
    "                             mode = 'lines',\n",
    "                             line = {\"color\": 'black',\n",
    "                                     \"width\": 2.},\n",
    "                             name = \"p90 conductivity\"))\n",
    "    fig.add_trace(go.Scatter(x = np.log10(D['cond_p50']),\n",
    "                             y = D['depth_cells'],\n",
    "                             mode = 'lines',\n",
    "                             line = {\"color\": 'gray',\n",
    "                                     \"width\": 2.,\n",
    "                                     'dash': 'dash'},\n",
    "                             name = \"p50 conductivity\"))\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def flightline_map(line):\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for linestring, lineNo in zip(gdf_lines.geometry, gdf_lines.lineNumber):\n",
    "\n",
    "        if int(lineNo) == int(line):\n",
    "            c = 'red'\n",
    "        else:\n",
    "            c = 'black'\n",
    "        x, y = linestring.xy\n",
    "\n",
    "        fig.add_trace(go.Scatter(x = list(x),\n",
    "                                 y = list(y),\n",
    "                                 mode = 'lines',\n",
    "                                 #hovertext = ['Line number = ' + str(lineNo)],\n",
    "                                 line = {\"color\": c,\n",
    "                                         \"width\": 2.},\n",
    "                                 name = str(lineNo)))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8060/\n"
     ]
    }
   ],
   "source": [
    "# you may need extra dependencies to run these cells\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "section_kwargs = {'colourbar_label': 'Conductivity (S/m)',\n",
    "                  'vmin': 0.01,\n",
    "                  'vmax': 1.,\n",
    "                  'cmap': 'jet'}\n",
    "\n",
    "stylesheet = \"https://codepen.io/chriddyp/pen/bWLwgP.css\"\n",
    "app = JupyterDash(__name__, external_stylesheets=[stylesheet])\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div(\n",
    "                [\n",
    "                    html.Div(html.H1(\"AEM interpretation dash board\"),\n",
    "                             className= \"four columns\"),\n",
    "                    html.Div([html.H4(\"Select section\"),\n",
    "                             dcc.Dropdown(id = \"section_dropdown\",\n",
    "                                            options=[\n",
    "                                                    {'label': 'laterally constrained inversion',\n",
    "                                                     'value': 'lci'},\n",
    "                                                    {'label': 'garjmcmctdem - p50',\n",
    "                                                     'value': 'rj-p50'},\n",
    "                                                   {'label': 'garjmcmcm - certainty',\n",
    "                                                     'value': 'rj-conf'},\n",
    "                                                    {'label': 'garjmcmctdem - layer probability',\n",
    "                                                     'value': 'rj-lpp'}],\n",
    "                                            value=\"lci\"),\n",
    "\n",
    "                             ],className = \"four columns\"),\n",
    "                    html.Div([html.H4(\"Select line\"),\n",
    "                             dcc.Dropdown(id = \"line_dropdown\",\n",
    "                                            options=line_options,\n",
    "                                            value= int(line_options[0]['label'])),\n",
    "                             ],className = \"four columns\")\n",
    "                ], className = 'row'\n",
    "            ),\n",
    "    html.Div(\n",
    "            [\n",
    "                html.Div(html.Pre(id='click-data'),\n",
    "                         className = \"four columns\"),\n",
    "                html.Div(className = \"four columns\"),\n",
    "                html.Div(html.Button('Update section', id='update', n_clicks=1),\n",
    "                         className= \"four columns\"),\n",
    "             ], className = \"row\"),\n",
    "    html.Div(\n",
    "        html.Div(\n",
    "            dcc.Graph(\n",
    "                id='section_plot',\n",
    "                figure = {}),\n",
    "        )\n",
    "    ),\n",
    "    html.Div([html.Div(\n",
    "        dash_table.DataTable(id='interp_table',\n",
    "                                    css=[{'selector': '.row', 'rule': 'margin: 0'}],\n",
    "                                    fixed_columns={ 'headers': True},#, 'data': 1 },\n",
    "                                    sort_action=\"native\",\n",
    "                                    sort_mode=\"multi\",\n",
    "                                    row_selectable=\"multi\",\n",
    "                                    row_deletable=True,\n",
    "                                    selected_columns=[],\n",
    "                                    selected_rows=[],\n",
    "                                    style_header={'backgroundColor': 'rgb(30, 30, 30)',\n",
    "                                               'height': '40px'},\n",
    "                                    style_cell={\n",
    "                                                 'backgroundColor': 'rgb(50, 50, 50)',\n",
    "                                                 'color': 'white',\n",
    "                                                 'minHeight': '50px',\n",
    "                                                 'minWidth': '0px', 'maxWidth': '800px',\n",
    "                                                 'whiteSpace': 'normal',\n",
    "                                                 'font-size': '12px'\n",
    "                                             },\n",
    "                                  style_table={\n",
    "                                              'maxHeight': '1000px',\n",
    "                                              'overflowY': 'scroll',\n",
    "                                              'maxWidth':  '1000px',\n",
    "                                              'overflowX': 'scroll'})\n",
    "                                        , className = \"four columns\"),\n",
    "        html.Div(html.Div(id='poly_line_plot'), className = \"four columns\"),\n",
    "        html.Div(html.Div(id='pmap'), className = \"four columns\"),]\n",
    "\n",
    "             ),\n",
    "\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('interp_table', 'data'),\n",
    "    Output('interp_table', 'columns')],\n",
    "    [Input(\"line_dropdown\", 'value'),\n",
    "     Input(\"update\", 'n_clicks')])\n",
    "def update_data_table(value, nclicks):\n",
    "    if nclicks >0:\n",
    "        df_ss = subset_df_by_line(surface.interpreted_points,\n",
    "                                  line = value)\n",
    "        return df_ss.to_dict('records'), [{\"name\": i, \"id\": i} for i in df_ss.columns]\n",
    "\n",
    "@app.callback(\n",
    "    Output('section_plot', \"figure\"),\n",
    "    [Input(\"line_dropdown\", 'value'),\n",
    "     Input(\"section_dropdown\", 'value'),\n",
    "     Input('interp_table', \"derived_virtual_data\"),\n",
    "     Input('interp_table', \"derived_virtual_selected_rows\")])\n",
    "def update_section(line, section_plot, rows, derived_virtual_selected_rows):\n",
    "    # When the table is first rendered, `derived_virtual_data` and\n",
    "    # `derived_virtual_selected_rows` will be `None`. This is due to an\n",
    "    # idiosyncrasy in Dash (unsupplied properties are always None and Dash\n",
    "    # calls the dependent callbacks when the component is first rendered).\n",
    "    # So, if `rows` is `None`, then the component was just rendered\n",
    "    # and its value will be the same as the component's dataframe.\n",
    "    # Instead of setting `None` in here, you could also set\n",
    "    # `derived_virtual_data=df.to_rows('dict')` when you initialize\n",
    "    # the component.\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = surface.interpreted_points if rows is None else pd.DataFrame(rows)\n",
    "\n",
    "    colours = ['pink' if i in derived_virtual_selected_rows else 'white'\n",
    "              for i in range(len(dff))]\n",
    "\n",
    "    section_kwargs['section_plot'] = section_plot\n",
    "\n",
    "    fig = dash_section(line, dff, colours, section_kwargs)\n",
    "\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    [Output('poly_line_plot', 'children')],\n",
    "    [Input(\"line_dropdown\", 'value')])\n",
    "def update_polyline_plot(value):\n",
    "    fig = flightline_map(value)\n",
    "    return [\n",
    "        dcc.Graph(\n",
    "            id='polylines',\n",
    "            figure=fig\n",
    "            ),\n",
    "    ]\n",
    "\n",
    "@app.callback(\n",
    "    Output('click-data', 'children'),\n",
    "    [Input('section_plot', 'clickData'),\n",
    "     Input(\"line_dropdown\", 'value')])\n",
    "def update_interp_table(clickData, line):\n",
    "    if clickData is not None:\n",
    "        if clickData['points'][0]['curveNumber'] == 1:\n",
    "            eventxdata, eventydata = clickData['points'][0]['x'], clickData['points'][0]['y']\n",
    "            min_idx = np.argmin(np.abs(lci.section_data[line]['grid_distances'] - eventxdata))\n",
    "\n",
    "            easting = lci.section_data[line]['easting'][min_idx]\n",
    "            northing = lci.section_data[line]['northing'][min_idx]\n",
    "            elevation = lci.section_data[line]['elevation'][min_idx]\n",
    "            depth =  elevation - eventydata\n",
    "            fid = xy2fid(easting,northing, lci)\n",
    "\n",
    "            # append to the surface object interpreted points\n",
    "            interp = {'fiducial': fid,\n",
    "                      'inversion_name': \"lci\",\n",
    "                      'X': np.round(easting,0),\n",
    "                      'Y': np.round(northing,0),\n",
    "                      'DEPTH': np.round(depth,0),\n",
    "                      'ELEVATION': eventydata,\n",
    "                      'DEM': elevation,\n",
    "                      'UNCERTAINTY': np.nan, # TODO implement\n",
    "                      'Type': surface.Type,\n",
    "                     'BoundaryNm': surface.name,\n",
    "                     'BoundConf': surface.BoundConf,\n",
    "                     'BasisOfInt': surface.BasisOfInt,\n",
    "                     'OvrConf': surface.OvrConf,\n",
    "                     'OvrStrtUnt': surface.OvrStrtUnt,\n",
    "                     'OvrStrtCod': surface.OvrStrtCod,\n",
    "                     'UndStrtUnt': surface.UndStrtUnt,\n",
    "                     'UndStrtCod': surface.UndStrtCod,\n",
    "                     'WithinType': surface.WithinType,\n",
    "                     'WithinStrt': surface.WithinStrt,\n",
    "                     'WithinStNo': surface.WithinStNo,\n",
    "                     'WithinConf': surface.WithinConf,\n",
    "                     'InterpRef': surface.InterpRef,\n",
    "                     'Comment': surface.Comment,\n",
    "                     'SURVEY_LINE': line,\n",
    "                     'Operator': surface.Operator,\n",
    "                      \"point_index\": min_idx\n",
    "                       }\n",
    "            df = pd.DataFrame(interp, index = [0])\n",
    "\n",
    "            surface.interpreted_points = surface.interpreted_points.append(df)#, verify_integrity = True)\n",
    "\n",
    "            return \"Last interpretation was \", eventxdata, \" along line and \", eventydata, \" mAHD\"\n",
    "\n",
    "@app.callback(\n",
    "    Output('pmap', 'children'),\n",
    "    Input('section_plot', 'clickData'))\n",
    "def update_pmap_plot(clickData):\n",
    "    if clickData is not None:\n",
    "        if clickData['points'][0]['curveNumber'] == 3:\n",
    "            point_idx = clickData['points'][0]['pointIndex']\n",
    "            fig = dash_pmap_plot(point_idx)\n",
    "            return [\n",
    "                    dcc.Graph(\n",
    "                        id='pmap_plot',\n",
    "                        figure=fig\n",
    "                        ),\n",
    "                    ]\n",
    "\n",
    "app.run_server(mode='external', port=8060)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "D = netcdf_utils.extract_rj_sounding(rj, lci,\n",
    "                                         1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}