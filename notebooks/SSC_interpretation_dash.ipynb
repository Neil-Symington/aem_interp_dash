{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "import gc, sys, os\n",
    "sys.path.append(\"../scripts\")\n",
    "import spatial_functions\n",
    "import aem_utils\n",
    "import netcdf_utils\n",
    "import modelling_utils\n",
    "import plotting_functions as plots\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "# Dash dependencies\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the LCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual inversoin data are stored on disk as netcdf files. NetCDF is an efficient format for storing \n",
    "# self-describing containerised data. \n",
    "# The implementation of netcdf for AEM line data was done by Alex Ip using his geophys_utils package.\n",
    "# https://github.com/GeoscienceAustralia/geophys_utils/tree/master/geophys_utils\n",
    "\n",
    "\n",
    "root = r\"C:\\Users\\symin\\OneDrive\\Documents\\GA\\AEM\\LCI\"\n",
    "\n",
    "# Define path to the netcdf file\n",
    "infile = os.path.join(root, \"SouthernStuart_WB_MGA53.nc\")\n",
    "\n",
    "# Create an instance\n",
    "lci = aem_utils.AEM_inversion(name = 'Laterally Contrained Inversion (LCI)',\n",
    "                              inversion_type = 'deterministic',\n",
    "                              netcdf_dataset = netCDF4.Dataset(infile))\n",
    "\n",
    "# As these inversions have already been gridded we will add these raster datasets to the instance using the\n",
    "# load_lci_layer_grid() function. This function belongs to the AEM_inversion class.\n",
    "\n",
    "# Directory in which the grids are located\n",
    "infile = os.path.join(root, \"grids\\\\SSC_LCI_layer_grids.p\")\n",
    "\n",
    "# Run function\n",
    "lci.load_lci_layer_grids_from_pickle(infile)\n",
    "\n",
    "# Create polylines\n",
    "lci.create_flightline_polylines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the garjmcmctdem inversion and probe the results using the same syntax as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to netcdf file\n",
    "infile = r\"C:\\Users\\symin\\OneDrive\\Documents\\GA\\AEM\\rjmcmc\\SSC_vanilla_rjmcmc_pmaps.nc\"\n",
    "\n",
    "\n",
    "# Create instance\n",
    "rj = aem_utils.AEM_inversion(name = 'GARJMCMCTDEM',\n",
    "                             inversion_type = 'stochastic',\n",
    "                             netcdf_dataset = netCDF4.Dataset(infile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the lines we can grid the lci conductivity data onto vertical grids (known as sections)\n",
    "# this is the easiest way to visualise the AEM conuctivity in 2-dimensions\n",
    "\n",
    "# Assign the lci variables to grid\n",
    "grid_vars = ['conductivity', 'data_residual', 'depth_of_investigation']\n",
    "\n",
    "\n",
    "# Define the resolution of the sections\n",
    "xres, yres = 40., 5.\n",
    "\n",
    "# We will use the lines from the rj\n",
    "\n",
    "lines = rj.data['line'][:]\n",
    "\n",
    "# Define the output directory if saving the grids as hdf plots\n",
    "\n",
    "hdf5_dir = r\"C:\\Temp\\SSC_hdf5\"\n",
    "\n",
    "# if the directory doesn't exist, then create it\n",
    "if not os.path.exists(hdf5_dir):\n",
    "    os.mkdir(hdf5_dir)  \n",
    "\n",
    "# Gridding takes a few minutes so I pre-gridded them for you. The lci.grid_sections()\n",
    "# function below will do the gridding for you. Instead we will use the load_sectoin_from_file()\n",
    "# function, which loads hdf5 files produced using the grid_sections() function\n",
    "\n",
    "\n",
    "#lci.grid_sections(variables = grid_vars, lines = lines, xres = xres, yres = yres,\n",
    "#                  return_interpolated = True, save_hdf5 = True, hdf5_dir = hdf5_dir)\n",
    "\n",
    "lci.load_sections_from_file(hdf5_dir, grid_vars, lines = lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid the rj sections\n",
    "\n",
    "# Assign the lci variables to grid\n",
    "grid_vars = ['conductivity_p10', 'conductivity_p50', 'conductivity_p90', 'interface_depth_histogram']\n",
    "\n",
    "# Define the resolution of the sections\n",
    "xres, yres = 100., 2.\n",
    "\n",
    "# We will use the lines from the rj\n",
    "\n",
    "lines = np.unique(rj.data['line'][:].astype('int'))\n",
    "\n",
    "# Define the output directory if saving the grids as hdf plots\n",
    "\n",
    "hdf5_dir = r\"C:\\Temp\\SSC_hdf5_rj\"\n",
    "\n",
    "# if the directory doesn't exist, then create it\n",
    "if not os.path.exists(hdf5_dir):\n",
    "    os.mkdir(hdf5_dir)  \n",
    "\n",
    "#rj.grid_sections(variables = grid_vars, lines = lines, xres = xres, yres = yres,\n",
    "#                  return_interpolated = True, save_hdf5 = True, hdf5_dir = hdf5_dir)\n",
    "\n",
    "rj.load_sections_from_file(hdf5_dir, grid_vars, lines = lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualise the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Map plot\n",
    "\n",
    "Our first standard plot is an plot of gridded conductivity with the points inverted with GARJMCMCTDEM\n",
    "plotted as points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Setup your model\n",
    "\n",
    "Now we want to create a model boundary object for our interpreted surface. The easiest way to manage this is to have a separate instance the module boundary for every interface. This will allow us to produce eggs ready output files as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an modelled boundary instance\n",
    "\n",
    "headings = [\"inversion_name\",'X', 'Y', 'ELEVATION', \"DEM\", \"DEPTH\", \"UNCERTAINTY\", \"Type\",\n",
    "            \"BoundaryNm\", \"BoundConf\", \"BasisOfInt\", \"OvrConf\", \"OvrStrtUnt\", \"OvrStrtCod\", \"UndStrtUnt\",\n",
    "           \"UndStrtCod\", \"WithinType\", \"WithinStrt\", \"WithinStNo\", \"WithinConf\", \"InterpRef\",\n",
    "            \"Comment\", \"SURVEY_LINE\", \"Operator\"]\n",
    "\n",
    "interp_file = r\"C:\\temp\\Mereenie-Pertnjara_interface_interpreted_points.csv\"\n",
    "\n",
    "MP_surface = modelling_utils.modelled_boundary(name = 'Mereenie-Pertnjara interface',\n",
    "                                               outfile_path = interp_file,\n",
    "                                               interpreted_point_headings = headings)\n",
    "MP_surface.interpreted_points = pd.read_csv(interp_file, index_col = 0)\n",
    "# Define your surface\n",
    "surface = MP_surface\n",
    "\n",
    "# Assign attributes base on what you want to be\n",
    "# entered into the eggs database\n",
    "surface.Type = \"BASE_Cenozoic_TOP_Paleozoic\"\n",
    "surface.OvrStrtUnt = \"Pertnjara Formation\"\n",
    "surface.OvrStrtCod = 15098\n",
    "surface.UndStrtUnt = \"Mereenie Sandstone\"\n",
    "surface.UndStrtCod = 11667\n",
    "surface.Inversion_name = \"garjmcmtdem\"\n",
    "surface.BoundConf = \"M\"\n",
    "surface.BasisOfInt = \"IAEM\"\n",
    "surface.OvrConf = \"M\"\n",
    "surface.InterpRef = \"\"\n",
    "surface.Comment = \"\"\n",
    "surface.Operator = \"Neil Symington\"\n",
    "surface.WithinType = \"\"\n",
    "surface.WithinStrt = \"\"\n",
    "surface.WithinStNo = \"\"\n",
    "surface.WithinConf = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def interp2scatter(line, gridded_data, interpreted_points, easting_col = 'X',\n",
    "                   northing_col = 'Y', elevation_col = 'ELEVATION',\n",
    "                   line_col = 'SURVEY_LINE'):\n",
    "\n",
    "    mask = interpreted_points[line_col] == line\n",
    "    utm_coords = np.column_stack((gridded_data[line]['easting'],\n",
    "                                  gridded_data[line]['northing']))\n",
    "\n",
    "    dist, inds = spatial_functions.nearest_neighbours(interpreted_points[mask][[easting_col,northing_col]].values,\n",
    "                                                      utm_coords, max_distance=100.)\n",
    "\n",
    "    grid_dists = gridded_data[line]['grid_distances'][inds]\n",
    "    elevs = interpreted_points[mask][elevation_col].values\n",
    "    fids = interpreted_points[mask].index\n",
    "    return  grid_dists, elevs, fids\n",
    "\n",
    "def dash_section(line, section_data, df_interp, colours):\n",
    "    # Create the grid\n",
    "    fig = px.imshow(img = np.log10(lci.section_data[line]['conductivity']),\n",
    "                zmin = np.log10(0.001), zmax = np.log10(1.),\n",
    "                x = lci.section_data[line]['grid_distances'],\n",
    "                y = lci.section_data[line]['grid_elevations'],\n",
    "        color_continuous_scale='viridis', aspect = 'auto'\n",
    "    )\n",
    "\n",
    "    interpx, interpz, fids = interp2scatter(line, section_data,\n",
    "                                                              df_interp)\n",
    "\n",
    "    labels = [\"fiducial = \" + str(x) for x in fids]\n",
    "\n",
    "    fig.add_scatter(x = interpx,\n",
    "                    y = interpz,\n",
    "                    mode = 'markers',\n",
    "                   hovertext = labels,\n",
    "                    marker = {\"color\": colours})\n",
    "\n",
    "    # Reverse y-axis\n",
    "    fig.update_yaxes(autorange=True)\n",
    "\n",
    "    return fig\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# you may need extra dependencies to run these cells\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "line = lines[0]\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "df = surface.interpreted_points\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(html.H1(\"AEM interpretation dash board\")),\n",
    "                    dbc.Col(dbc.DropdownMenu(id = \"section_dropdown\",\n",
    "                                            label=\"Section\",\n",
    "                                            children=[\n",
    "                                                dbc.DropdownMenuItem(\"lci\"),\n",
    "                                                dbc.DropdownMenuItem(\"rjmcmc\")\n",
    "                                            ])),\n",
    "                    dbc.Col(dbc.DropdownMenu(id = \"line_dropdown\",\n",
    "                                            label=\"Line number\",\n",
    "                                            children=[\n",
    "                                                dbc.DropdownMenuItem(100101),\n",
    "                                                dbc.DropdownMenuItem(100201),\n",
    "                                            ]))\n",
    "                ]\n",
    "                 ),\n",
    "    dbc.Row(dbc.Col(id='section')),\n",
    "    dbc.Row(dbc.Col(dash_table.DataTable(id='interp_table',\n",
    "                                    columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "                                    data=df.to_dict('records'),\n",
    "                                 fixed_columns={ 'headers': True, 'data': 1 },\n",
    "                                 sort_action=\"native\",\n",
    "                                 sort_mode=\"multi\",\n",
    "                                 column_selectable=\"multi\",\n",
    "                                 row_selectable=\"multi\",\n",
    "                                 row_deletable=True,\n",
    "                                 selected_columns=[],\n",
    "                                 selected_rows=[],\n",
    "                                 style_header={'backgroundColor': 'rgb(30, 30, 30)',\n",
    "                                               'height': '70px'},\n",
    "                                 style_cell={\n",
    "                                     'backgroundColor': 'rgb(50, 50, 50)',\n",
    "                                     'color': 'white',\n",
    "                                     'minHeight': '50px',\n",
    "                                     'minWidth': '0px', 'maxWidth': '800px',\n",
    "                                     'whiteSpace': 'normal'\n",
    "                                 },\n",
    "                                  style_table={\n",
    "                                              'maxHeight': '1000px',\n",
    "                                              'overflowY': 'scroll',\n",
    "                                              'maxWidth':  '1000px',\n",
    "                                              'overflowX': 'scroll'})\n",
    "             )),\n",
    "],fluid=True)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('section', \"children\"),\n",
    "    [Input('interp_table', \"derived_virtual_data\"),\n",
    "     Input('interp_table', \"derived_virtual_selected_rows\")])\n",
    "def update_graphs(rows, derived_virtual_selected_rows):\n",
    "    # When the table is first rendered, `derived_virtual_data` and\n",
    "    # `derived_virtual_selected_rows` will be `None`. This is due to an\n",
    "    # idiosyncrasy in Dash (unsupplied properties are always None and Dash\n",
    "    # calls the dependent callbacks when the component is first rendered).\n",
    "    # So, if `rows` is `None`, then the component was just rendered\n",
    "    # and its value will be the same as the component's dataframe.\n",
    "    # Instead of setting `None` in here, you could also set\n",
    "    # `derived_virtual_data=df.to_rows('dict')` when you initialize\n",
    "    # the component.\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = df if rows is None else pd.DataFrame(rows)\n",
    "\n",
    "    colours = ['red' if i in derived_virtual_selected_rows else 'blue'\n",
    "              for i in range(len(dff))]\n",
    "\n",
    "    fig = dash_section(line, lci.section_data, dff, colours)\n",
    "\n",
    "    return [\n",
    "        dcc.Graph(\n",
    "            id='graph',\n",
    "            figure=fig\n",
    "            ),\n",
    "    ]\n",
    "\n",
    "app.run_server(mode='external')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "surface.interpreted_points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}