{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, MultiPoint, Polygon\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from shapely.wkt import loads\n",
    "from scipy.spatial.ckdtree import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import netCDF4\n",
    "import h5py\n",
    "import gc, sys, os\n",
    "import glob\n",
    "import string\n",
    "import json\n",
    "sys.path.append(\"..\\scripts\")\n",
    "import spatial_functions\n",
    "import aem_utils\n",
    "import netcdf_utils\n",
    "import modelling_utils\n",
    "import plotting_functions as plots\n",
    "import ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this notebook environment, the inversions we will be using will be instances of the AEM_inversion class. A class is a feature of python programming that allows the bundling of data with functionality. Here we use two inversions, the deterministic laterally constrained inversion and the stochastic GA reversible-jump Markov Chain Monte Carlo TDEM (GARJMCMCTDEM) inversion. We will demonstrate how to access these inversions by creating an instnace of the AEM class for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual inversoin data are stored on disk as netcdf files. This is an efficient format for storing self-describing containerised data. \n",
    "# The implementation of netcdf for AEM line data was done by Alex Ip using his geophys_utils package.\n",
    "# https://github.com/GeoscienceAustralia/geophys_utils/tree/master/geophys_utils\n",
    "\n",
    "# Define path to the netcdf file\n",
    "infile = r\"C:\\Users\\PCUser\\Desktop\\AEM\\LCI\\DalyR_WB_MGA52.nc\"\n",
    "\n",
    "# Create an instance\n",
    "lci = aem_utils.AEM_inversion(name = 'Laterally Contrained Inversion (LCI)',\n",
    "                              inversion_type = 'deterministic',\n",
    "                              netcdf_dataset = netCDF4.Dataset(infile))\n",
    "\n",
    "# Ass these inversions have already been gridded we will add these raster datasets to the instance using the\n",
    "# load_lci_layer_grid() function. This function belongs to the AEM_inversion class.\n",
    "\n",
    "# Directory in which the grids are located\n",
    "inRaster = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\2017_DalyRiver_SkyTEM\\03_LCI\\03_Depth_Slices\\Grids_doi_Masked\"\n",
    "\n",
    "# Run function\n",
    "lci.load_lci_layer_grids(inRaster, conversion_to_SI = True, nlayers = 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let examine the results of this process. We can view the contents of the netcdf file by simply printing the 'data' attribute\n",
    "within a cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    geospatial_east_min: 684789.625\n",
      "    geospatial_east_max: 910249.5\n",
      "    geospatial_east_units: m\n",
      "    geospatial_north_min: 8309173.0\n",
      "    geospatial_north_max: 8495335.0\n",
      "    geospatial_north_units: m\n",
      "    title: Dataset read from ASEG-GDF file DalyR_WB_MGA52_temp.dat\n",
      "    Conventions: CF-1.6,ACDD-1.3\n",
      "    featureType: trajectory\n",
      "    geospatial_vertical_min: \n",
      "    geospatial_vertical_max: 302.2\n",
      "    geospatial_vertical_units: m\n",
      "    geospatial_vertical_resolution: point\n",
      "    geospatial_vertical_positive: up\n",
      "    history: Converted from ASEG-GDF file C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\2017_DalyRiver_SkyTEM\\03_LCI\\01_Data\\DalyR_WB_MGA52_temp.dat using definitions file C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\2017_DalyRiver_SkyTEM\\03_LCI\\01_Data\\DalyR_WB_MGA52.dfn\n",
      "    date_created: 2019-10-07T16:54:15.324169\n",
      "    geospatial_east_resolution: point\n",
      "    geospatial_north_resolution: point\n",
      "    geospatial_bounds: POLYGON((132.3612 -15.2686, 131.9411 -15.2494, 131.7248 -15.2028, 130.9303 -14.5171, 130.7118 -14.1104, 130.7116 -13.7691, 130.7611 -13.6145, 131.1826 -13.6011, 131.4240 -13.6121, 132.8088 -14.7304, 132.5415 -15.2508, 132.3612 -15.2686))\n",
      "    keywords: geophysics, airborne, AEM, conductivity\n",
      "    geospatial_lon_min: 130.71160040346342\n",
      "    geospatial_lon_max: 132.80881437819602\n",
      "    geospatial_lon_units: degrees East\n",
      "    geospatial_lat_min: -15.268608354328533\n",
      "    geospatial_lat_max: -13.60106615168933\n",
      "    geospatial_lat_units: degrees North\n",
      "    dimensions(sizes): point(124422), layer(30), comments(3), line(143)\n",
      "    variables(dimensions): int8 transverse_mercator(), <class 'str'> comments(comments), int8 comments_index(point), float32 flight_line(point), float64 ga_proj(), float64 job_no(), float32 fid(point), float64 DateTime(point), float64 line(line), int32 line_index(point), float32 easting(point), float32 northing(point), float32 elevation(point), float32 data_residual(point), float32 tx_height_measured(point), float32 tx_height_inverted(point), float32 depth_of_investigation(point), float32 layer_top_elevation(point,layer), float32 conductivity(point,layer), float32 conductivity_(masked_to_DOI)(point,layer), float32 conductivity_uncertainty(point,layer), float32 tmi_igrf(point), int8 crs(), float64 longitude(point), float64 latitude(point), float64 layer_top_depth(point,layer)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "print(lci.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the garjmcmctdem inversion and probe the results using the same syntax as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to netcdf file\n",
    "infile = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\garj_workshop2\\DR_rjmcmc_pmaps.nc\"\n",
    "\n",
    "# Create instance\n",
    "rj = aem_utils.AEM_inversion(name = 'GARJMCMCTDEM',\n",
    "                              inversion_type = 'stochastic',\n",
    "                              netcdf_dataset = netCDF4.Dataset(infile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    nlayers_min: 1\n",
      "    nlayers_max: 25\n",
      "    nsamples: 500000\n",
      "    nchains: 8\n",
      "    nburnin: 50000\n",
      "    thinrate: 10\n",
      "    min_log10_conductivity: -3.0\n",
      "    max_log10_conductivity: 0.0\n",
      "    min_depth: 0.0\n",
      "    max_depth: 400.0\n",
      "    value_parameterization: LOG10\n",
      "    position_parameterization: LINEAR\n",
      "    keywords: geophysics, airborne, AEM, conductivity, garjmcmcmtdem\n",
      "    date_created: 2020-07-15 00:12:57.153566\n",
      "    crs: GDA94 / MGA zone 52\n",
      "    crs_geographic: GDA2020\n",
      "    geospatial_east_min: 736897.38\n",
      "    geospatial_east_max: 838798.69\n",
      "    geospatial_east_units: m\n",
      "    geospatial_north_min: 8363871.0\n",
      "    geospatial_north_max: 8469587.0\n",
      "    geospatial_north_units: m\n",
      "    geospatial_vertical_min: 36.81\n",
      "    geospatial_vertical_max: 155.63\n",
      "    geospatial_vertical_units: m\n",
      "    geospatial_lon_min: 131.191645950018\n",
      "    geospatial_lon_max: -13.833624150977913\n",
      "    geospatial_lont_units: degrees North\n",
      "    geospatial_lat_min: -14.777824330086071\n",
      "    dimensions(sizes): point(326), data(41), depth(100), conductivity_cells(100), layer(25), chain(8), convergence_sample(50010)\n",
      "    variables(dimensions): float64 easting(point), float64 northing(point), float64 latitude(point), float64 longitude(point), float64 line(point), float64 elevation(point), float64 fiducial(point), float64 utc_date(point), float64 flight(point), uint32 nlayers_min(), uint32 nlayers_max(), uint32 nsamples(), uint32 nchains(), uint32 nburnin(), uint32 thinrate(), float64 min_log10_conductivity(), float64 max_log10_conductivity(), float64 min_depth(), float64 max_depth(), float64 data_values(point,data), float64 data_absolute_uncertainty(point,data), float64 layer_centre_depth(depth), float64 cond_bin_centre(conductivity_cells), uint32 log10conductivity_histogram(point,depth,conductivity_cells), uint32 interface_depth_histogram(point,depth), uint32 nlayers_histogram(point,layer), float32 misfit(point,chain,convergence_sample), float32 conductivity_mean(point,depth), float32 conductivity_mode(point,depth), float32 conductivity_p10(point,depth), float32 conductivity_p50(point,depth), float32 conductivity_p90(point,depth)\n",
      "    groups: \n",
      "This inversions is named  GARJMCMCTDEM\n",
      "The most south-west point in the survey has coordinates of (736897.38,8363871.0)\n"
     ]
    }
   ],
   "source": [
    "# here we print a few of the attributes\n",
    "print(rj.data)\n",
    "print(\"This inversions is named \", rj.name)\n",
    "print(\"The most south-west point in the survey has coordinates of (\" + str(rj.xmin) + ',' + str(rj.ymin) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102201 102301 102401 102501 102701 102801 102901 103001 103101 103201\n",
      " 103301 103401 103501 103502 103601 103701 103801 103901 104001 104101\n",
      " 104102 104201 104301 104401 104501 104601 104701 104801 104901 105001\n",
      " 105101 105201 105301 105401 105501 105602 105701 105801 105901 105902\n",
      " 106001 106101 106201 106301 106401 108001 108601 109203 109302 109401\n",
      " 109502 109601 109701 110102 110103 110201 912005]\n"
     ]
    }
   ],
   "source": [
    "# Now we have the lines we can grid the lci conductivity data onto vertical grids (known as sections)\n",
    "# this is the easiest way to visualise the AEM conuctivity in 2-dimensions\n",
    "\n",
    "grid_vars = ['conductivity', 'data_residual']\n",
    "\n",
    "# Define the resolution of th sections\n",
    "xres, yres = 20., 4.\n",
    "\n",
    "# We will use the lines from the rj\n",
    "\n",
    "lines = np.unique(rj.data['line'][:].astype('int'))\n",
    "\n",
    "print(lines)\n",
    "\n",
    "# Define the output directory if saving the grids as hdf plots\n",
    "\n",
    "hdf5_dir = r\"C:\\Users\\PCUser\\Desktop\\NSC_data\\data\\AEM\\DR\\lci\\hdf5\"\n",
    "\n",
    "if not os.path.exists(hdf5_dir):\n",
    "    os.mkdir(hdf5_dir)\n",
    "\n",
    "    \n",
    "### TODO add a load_sections_from_hdf5 functino\n",
    "lci.grid_sections(variables = grid_vars, lines = lines, xres = xres, yres = yres,\n",
    "                  return_interpolated = True, save_hdf5 = True, hdf5_dir = hdf5_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's quickly visualise the data. You can easily create your own plots if you are comfortable with the matplotlib python \n",
    "package. However, you may prefer to use some of the standard plots. Here we create an interactive plot that allows us to \n",
    "store the point index of a scatter point if we click on it. This point index becomes useful for visualising individual points\n",
    " if the points are not readily accesible through a GIS software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0570cd323ec4e22aeca35f4faf7b45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets plot the distribution of the points. Clicking on one will return the point index\n",
    "\n",
    "# This is an interactive function that returns the index of a point if it is clicked on.\n",
    "def on_map_click(event):\n",
    "    global point_index\n",
    "    if event.xdata != None:\n",
    "        x_, y_ = event.xdata, event.ydata\n",
    "        distances, indices = spatial_functions.nearest_neighbours([x_,y_], rj.coords, max_distance = 5000.)\n",
    "        point_index = indices[0]\n",
    "        points.append(point_index)\n",
    "        print('Point index is ', point_index)\n",
    "        \n",
    "# In this notebook, standard plot key word arguments are passed to the plotting function as a python dictionary\n",
    "\n",
    "# Here we explain each variable. Feel free to change and regenerate the plot\n",
    "plot_args = {'Layer_number': 1, # Which AEM layer grid to plot from layer 1 (shallowest) to 30 (deepest)\n",
    "             \"figsize\": (12,12), # The figure size in inches\n",
    "             \"vmin\": 0.001, \"vmax\": 0.1, # The maximum and minimum conductivities in (S/m) for the grid colourstretch\n",
    "             \"point_size\": 4, \"point_colour\": 'black', # Size and colour of the scatter plot points\n",
    "             'colour_stretch': 'jet', # See matplotlib colourstretches\n",
    "              'buffer': 500.} # The plot boundary will be buffered around the outer most scatter points.\n",
    "\n",
    "plt.close('all')\n",
    "# Do some plotting\n",
    "\n",
    "fig, ax, cax = plots.AEM_baseplot(rj, lci, plot_args = plot_args)\n",
    "\n",
    "# You can edit the ax (grid panel) and cax (colourbar axis) using matplotlib axis function\n",
    "# for example uncomment and run the follwoing line\n",
    "#ax.set_xlim(740000, 760000)\n",
    "\n",
    "cid =  fig.canvas.mpl_connect('button_press_event', on_map_click)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create a model boundary object for our interpreted surface. As with AEm inversions our interpreted surface will be\n",
    "an instance of a python class. However, this class is called modelled boundary and has different data and funcionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an modelled boundary instance\n",
    "surface = None\n",
    "surface = modelling_utils.modelled_boundary(name = 'Oolloo-Jinduckin interface - elevation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75, 8, 30, 96, 118, 227, 222, 218, 318, 315, 259, 234, 297, 325]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often there wil be some point saved to disk. These may have been interpretation points\n",
    "from another session or from another source. These can be loaded with the load_interpretation_points_from_file()\n",
    "function. It is important that the schema of this file is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           fiducial        easting      northing  layer_depth  \\\n",
      "count  3.900000e+01      39.000000  3.900000e+01    39.000000   \n",
      "mean   1.198074e+06  752335.933846  8.443647e+06   246.000000   \n",
      "std    8.596588e+04    7129.251112  1.000542e+04    66.655438   \n",
      "min    1.124803e+06  741491.690000  8.423438e+06    54.000000   \n",
      "25%    1.129939e+06  747193.280000  8.436798e+06   206.000000   \n",
      "50%    1.140876e+06  750940.940000  8.445595e+06   246.000000   \n",
      "75%    1.301906e+06  756673.470000  8.451102e+06   290.000000   \n",
      "max    1.389236e+06  772582.120000  8.458588e+06   366.000000   \n",
      "\n",
      "       layer_elevation  standard_deviation  \n",
      "count        39.000000           39.000000  \n",
      "mean       -172.606410           19.756362  \n",
      "std          72.180187           13.228974  \n",
      "min        -312.660000            3.397287  \n",
      "25%        -228.215000            8.493218  \n",
      "50%        -152.230000           15.287792  \n",
      "75%        -127.200000           30.575585  \n",
      "max           5.010000           50.000000  \n",
      "    fiducial    easting  northing  layer_depth  layer_elevation  \\\n",
      "0  1124803.0  742111.75   8458588          166          -121.17   \n",
      "1  1125963.5  747129.81   8457582          182          -102.67   \n",
      "2  1126151.0  741491.69   8457586          186          -134.48   \n",
      "\n",
      "   standard_deviation  \n",
      "0           15.287792  \n",
      "1           15.287792  \n",
      "2            8.493218  \n"
     ]
    }
   ],
   "source": [
    "# path to csv file\n",
    "infile = r\"C:\\Temp\\pmap_interp\\rj_interp.csv\"\n",
    "\n",
    "# now lets examine the file using a package called pandas. This\n",
    "# package excels at processing tabular data such like our point data\n",
    "\n",
    "# load the data into \"dataframe\", which is a pandas object\n",
    "df_pts = pd.read_csv(infile)\n",
    "\n",
    "# print the dataframe summary statistics and top three rows\n",
    "print(df_pts.describe())\n",
    "print(df_pts.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modelling_utils' from '..\\\\scripts\\\\modelling_utils.py'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(modelling_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are satisfied we can load the points\n",
    "\n",
    "surface = modelling_utils.modelled_boundary(name = 'Oolloo-Jinduckin interface - elevation')\n",
    "\n",
    "surface.load_interpretation_points_from_file(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_elevation\n",
      "standard_deviation\n"
     ]
    }
   ],
   "source": [
    "# Our surface will be modelled onto a grid which we will define\n",
    "# based on our own project objectives\n",
    "\n",
    "# Define the grid bounds\n",
    "ymin, ymax, = 8420000, 8460000\n",
    "xmin, xmax = 740000, 778000\n",
    "cell_size = 500.\n",
    "\n",
    "# If the surface is not converging it is definitely worth playing with these lenth scales \n",
    "kernels = [Matern(nu = 1.5, length_scale_bounds = [1000,10000]),\n",
    "           Matern(nu = 1.5, length_scale_bounds = [2000,10000])]\n",
    "\n",
    "convex_hull_buffer = 1000.\n",
    "inteporlation_variables = ['layer_elevation', 'standard_deviation']\n",
    "\n",
    "# Create our regular grid\n",
    "surface.create_grid(xmin, xmax, ymin, ymax, cell_size = cell_size, convex_hull = True,\n",
    "                   convex_hull_buffer = convex_hull_buffer)\n",
    "\n",
    "\n",
    "# No lets interpolate both variables in inteporlation_variables\n",
    "\n",
    "# Loop through them\n",
    "\n",
    "for i, var in enumerate(inteporlation_variables):\n",
    "    \n",
    "    # Create an interpolator for gridding point data. Thus far I have only implemented a Gaussian Process\n",
    "    interpolator_name = var + \"_gp\"\n",
    "    \n",
    "    grid_name = var + '_grid'\n",
    "    \n",
    "    print(var)\n",
    "    \n",
    "    surface.create_interpolator(kernel = kernels[i],\n",
    "                                name = interpolator_name)\n",
    "\n",
    "    # If we have points we can fit our interpolation\n",
    "\n",
    "    surface.fit_interpolator(variable = var,\n",
    "                             interpolator_name = interpolator_name)\n",
    "\n",
    "    surface.predict_on_grid(interpolator_name = interpolator_name, \n",
    "                            grid_name = grid_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe166bdbf9e4d749ee1dd110d924cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(6,6))\n",
    "im = ax.imshow(surface.layer_elevation_grid_std)\n",
    "cax = fig.add_axes([0.9, 0.25, 0.02, 0.6])\n",
    "cb = fig.colorbar(im, cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'bounds',\n",
       " 'cell_size',\n",
       " 'convex_hull',\n",
       " 'create_grid',\n",
       " 'create_interpolator',\n",
       " 'fit_interpolator',\n",
       " 'get_convex_hull',\n",
       " 'grid_coords',\n",
       " 'height',\n",
       " 'interpreted_points',\n",
       " 'layer_elevation_gp',\n",
       " 'layer_elevation_grid',\n",
       " 'layer_elevation_grid_std',\n",
       " 'load_interpretation_points_from_file',\n",
       " 'name',\n",
       " 'outfile_path',\n",
       " 'predict_at_points',\n",
       " 'predict_on_grid',\n",
       " 'save_points',\n",
       " 'standard_deviation_gp',\n",
       " 'standard_deviation_grid',\n",
       " 'standard_deviation_grid_std',\n",
       " 'width']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(surface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these grids as we update the points. To make this easier the interpreted_surface_dual_plot() updates the interpolation and plots the results for two variables. Below we demonstrate on layer_elevation and standard_deviation variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c361e21bc76149a0bd1b5009e2128402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Once again the plot arguments are given as a dictionary.\n",
    "# here we define one for each panel. We incl\n",
    "plot_args = {'Panel_1': {'variable': 'layer_elevation',\n",
    "                         'grid': 'layer_elevation_grid',\n",
    "                         'interpolator': 'layer_elevation_gp',\n",
    "                          \"vmin\": -300., \"vmax\": 0.,\n",
    "                         'colour_stretch': 'viridis'},\n",
    "             \n",
    "            'Panel_2': {'variable': 'standard_deviation',\n",
    "                         'grid': 'standard_deviation_grid',\n",
    "                         'interpolator': 'standard_deviation_gp',\n",
    "                         \"vmin\": 0., \"vmax\": 50.,\n",
    "                         'colour_stretch': 'magma_r'}}\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fig, ax_array, cax_array = plots.interpreted_surface_dual_plot(surface, plot_args = plot_args,\n",
    "                                                               update_grid = True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function stores the top of the conductor in the dataframe on a click\n",
    "outdir = r\"C:\\temp\\pmap_interp\"\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "outfile = os.path.join(outdir, \"rj_interp_.csv\")    \n",
    "\n",
    "# This function finds the width of the porbability interval that is >0.5\n",
    "# times the local max probability\n",
    "def full_width_half_max(max_idx, fmax):\n",
    "    \n",
    "    idx_upper = None\n",
    "    idx_lower = None\n",
    "    \n",
    "    # positive direction\n",
    "    for idx in np.arange(max_idx, D['depth_cells'].shape[0]):\n",
    "        if D['change_point_pdf'][idx] <= fmax/2.:\n",
    "            idx_upper = idx\n",
    "            break\n",
    "    # negative direction\n",
    "    for idx in np.arange(max_idx, -1, -1):\n",
    "        if D['change_point_pdf'][idx] <= fmax/2.:\n",
    "            idx_lower = idx\n",
    "            break\n",
    "    # Now calculate the width\n",
    "    if np.logical_and(idx_upper is not None, idx_lower is not None):\n",
    "        return D['depth_cells'][idx_upper] - D['depth_cells'][idx_lower]\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    \n",
    "\n",
    "# Function for snapping to a layer point probability maximum\n",
    "# from a click\n",
    "def click2estimate(yclick):\n",
    "    snap_window = 16\n",
    "    ymin = yclick - snap_window/2\n",
    "    ymax = yclick + snap_window/2\n",
    "    \n",
    "    # Get the change point probability array for the snap window interval\n",
    "    \n",
    "    idx = np.where(np.logical_and(D['depth_cells']>ymin, D['depth_cells']<ymax))\n",
    "    \n",
    "    # Now find the maximum cpp from this range\n",
    "    idx_max = np.argmax(D['change_point_pdf'][idx]) + np.min(idx)\n",
    "    fmax = D['change_point_pdf'][idx_max]\n",
    "    interpreted_depth = D['depth_cells'][idx_max]\n",
    "    \n",
    "    # from https://en.wikipedia.org/wiki/Full_width_at_half_maximum\n",
    "    fwhm = full_width_half_max(idx_max, fmax)\n",
    "    \n",
    "    if fwhm is not None:\n",
    "        stdev = fwhm/(2*np.sqrt(2*np.log(2)))\n",
    "    else:\n",
    "        stdev = 50.\n",
    "    return interpreted_depth, stdev\n",
    "\n",
    "# Find the nearest neighbours within the maximum distance\n",
    "\n",
    "def xy_2_var(grid_dict, xy, var):\n",
    "    \"\"\"\n",
    "    Function for finding a variable for gridded AEM sections\n",
    "    given an input easting and northing\n",
    "    @ param: grid_dict :dictionary for gridded line data\n",
    "    @ param: xy: numpy array with easting and northing\n",
    "    @ param: var: string with variable name\n",
    "    returns\n",
    "    float: distance along line\n",
    "    \"\"\"\n",
    "    utm_coords = np.column_stack((grid_dict['easting'],\n",
    "                                  grid_dict['northing']))\n",
    "\n",
    "    d, i = spatial_functions.nearest_neighbours(xy,\n",
    "                                                utm_coords,\n",
    "                                                points_required=1,\n",
    "                                                max_distance=100.)\n",
    "    if np.isnan(d[0]):\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        near_ind = i[0]\n",
    "    \n",
    "\n",
    "\n",
    "        return grid_dict[var][near_ind]\n",
    "\n",
    "\n",
    "def pmap_click(event):\n",
    "    if event.xdata != None and event.ydata != None:\n",
    "        #We will use fiducial as a key\n",
    "        fid = D['fiducial']\n",
    "        depth, stdev = click2estimate(event.ydata)\n",
    "        interpretations[fid] = {'easting': D['easting'],\n",
    "                                'northing':  D['northing'],\n",
    "                                'layer_depth': np.round(depth,0),\n",
    "                                'layer_elevation': np.round(D['elevation'] - event.ydata,2),\n",
    "                                'standard_deviation': np.round(stdev,0)\n",
    "                               }\n",
    "        # Save the interpretation\n",
    "        pd.DataFrame(interpretations).transpose().to_csv(outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_index = 233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1301955.5: {'easting': 753664.12,\n",
       "  'northing': 8436563.0,\n",
       "  'layer_depth': 226.0,\n",
       "  'layer_elevation': -165.88,\n",
       "  'standard_deviation': 7.0}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretations# = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b4c4bdafab4855a789a42771f7a597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-694c08d8ee5c>:64: RuntimeWarning: divide by zero encountered in log10\n",
      "  ax1.plot(np.log10(lci_expanded), depth_expanded, c = 'pink',\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "D = netcdf_utils.extract_rj_sounding(rj, lci, point_index)\n",
    "\n",
    "line = np.int(rj.data['line'][point_index].data)\n",
    "\n",
    "# Find distance along the lci section\n",
    "dist = xy_2_var(lci.section_data[line],\n",
    "                 np.array([[D['easting'], D['northing']]]),\n",
    "                 'grid_distances')\n",
    "\n",
    "\n",
    "point_ind_lci = dist\n",
    "\n",
    "fig, ax_array = pmap_plot(D)\n",
    "\n",
    "point_index += 5 \n",
    "\n",
    "plt.show()\n",
    "\n",
    "cid=  fig.canvas.mpl_connect('button_press_event', pmap_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO... Add this to the repo using a dictionary as the input\n",
    "def pmap_plot(D, outfile = None):\n",
    "    \n",
    "    figsize = (12,10)\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "\n",
    "    # These are for interactive widget mode\n",
    "    fig.canvas.layout.width = str(figsize[0]) + 'in'\n",
    "    fig.canvas.layout.height= str(figsize[1]) + 'in'\n",
    "\n",
    "    ax1 = fig.add_axes([0.05, 0.35, 0.35, 0.62])\n",
    "    ax2 = fig.add_axes([0.45, 0.35, 0.2, 0.62])\n",
    "    ax3 = fig.add_axes([0.70, 0.52, 0.2, 0.2])\n",
    "    ax4 = fig.add_axes([0.72, 0.32, 0.16, 0.16])\n",
    "    ax5 = fig.add_axes([0.1, 0.18, 0.76, 0.05])\n",
    "    ax6 = fig.add_axes([0.1, 0.05, 0.76, 0.13])\n",
    "    ax7 = fig.add_axes([0.70, 0.78, 0.2, 0.2])\n",
    "    cbar_ax1 = fig.add_axes([0.05, 0.29, 0.35, 0.01])\n",
    "    cbar_ax2 = fig.add_axes([0.88, 0.05, 0.01, 0.2])\n",
    "    cbar_ax3 = fig.add_axes([0.9, 0.52, 0.01, 0.2])\n",
    "    \n",
    "    panel_kwargs = [{'title': '',\n",
    "                      'color': 'black',\n",
    "                      'ylabel': 'data \\n residual',\n",
    "                      'legend': False},\n",
    "                     {'title': 'LCI conductivity',\n",
    "                      'max_depth': 500.,\n",
    "                      'shade_doi': True,\n",
    "                      'colourbar': True,\n",
    "                      'colourbar_label': 'Conductivity (S/m)',\n",
    "                      'log_plot': True,\n",
    "                      'vmin': 0.001,\n",
    "                      'vmax': 2.,\n",
    "                      'cmap': 'jet',\n",
    "                      'ylabel': 'elevation \\n (mAHD)',\n",
    "                      'vertical_exaggeration': 1.0}]\n",
    "\n",
    "\n",
    "    # Plot probability map\n",
    "    \n",
    "    # ax1\n",
    "    im = ax1.imshow(D['conductivity_pdf'], extent = D['conductivity_extent'],\n",
    "                    aspect = 'auto', cmap = 'rainbow')\n",
    "    \n",
    "    #  PLot the median, and percentile plots\n",
    "    ax1.plot(np.log10(D['cond_p10']), D['depth_cells'], c = 'k',linestyle='dashed', label = 'p10')\n",
    "    ax1.plot(np.log10(D['cond_p90']), D['depth_cells'], c = 'k',linestyle='dashed', label = 'p90')\n",
    "    ax1.plot(np.log10(D['cond_p50']), D['depth_cells'], c = 'k',label = 'p50')\n",
    "    ax1.plot(np.log10(D['cond_mean']), D['depth_cells'], c = 'grey',label = 'mean')\n",
    "    \n",
    "    ax1.set_xticklabels([round(10 ** float(x), 4) for x in ax1.get_xticks()])\n",
    "\n",
    "    # for lci layered model we do some processing\n",
    "    lci_expanded = np.zeros(shape=2 * len(D['lci_cond']) + 1,\n",
    "                                 dtype=np.float)\n",
    "\n",
    "    lci_expanded[1:] = np.repeat(D['lci_cond'], 2)\n",
    "\n",
    "    depth_expanded = (np.max(D['lci_depth_top']) + 10) * np.ones(shape=len(lci_expanded),\n",
    "                                                            dtype=np.float)\n",
    "\n",
    "    depth_expanded[:-1] = np.repeat(D['lci_depth_top'], 2)\n",
    "\n",
    "    ax1.plot(np.log10(lci_expanded), depth_expanded, c = 'pink',\n",
    "             linestyle = 'dashed', label = 'lci')\n",
    "    ax1.plot(ax1.get_xlim(), [D['lci_doi'], D['lci_doi']], c = 'yellow',\n",
    "             label = 'LCI doi')\n",
    "    ax1.set_title('rj-MCMC probability map')\n",
    "    ax1.set_ylabel('depth (mBGL)')\n",
    "    ax1.set_xlabel('Conductivity (S/m)')\n",
    "    ax1.grid(which = 'both')\n",
    "    ax1.set_xlim(D['conductivity_extent'][0], D['conductivity_extent'][1] )\n",
    "    \n",
    "    ax1.set_ylim(D['conductivity_extent'][2], D['conductivity_extent'][3])#100.,0)#\n",
    "\n",
    "    ax1.legend(loc = 3)\n",
    "    \n",
    "    # Ax 2\n",
    "    ax2.plot(D['change_point_pdf'], D['depth_cells'], label = 'P(change point)')\n",
    "    ax2.set_ylim(ax2.get_ylim()[::-1])\n",
    "    ax2.set_yticks(np.arange(0, 500, 20.))\n",
    "    ax2.set_title('change point probability')\n",
    "    ax2.set_ylim(D['conductivity_extent'][2], D['conductivity_extent'][3])#(100.,0)\n",
    "\n",
    "    ax2.legend()\n",
    "    ax2.grid(which = 'both')\n",
    "    \n",
    "    elevation_grid = surface.layer_elevation_grid\n",
    "    extent = surface.bounds\n",
    "    \n",
    "    im3 = ax3.imshow(elevation_grid,extent = extent, vmin = -300, vmax = 0)\n",
    "    \n",
    "    ax3.scatter(surface.interpreted_points['easting'],\n",
    "                surface.interpreted_points['northing'], c='k',\n",
    "                marker = '+')\n",
    "\n",
    "    ax3.plot(D['easting'],D['northing'],  'x', c = 'red')\n",
    "    \n",
    "    ax\n",
    "    \n",
    "    # Ax 4\n",
    "    sample = D['sample_no'][:]\n",
    "    \n",
    "    # Add the misfit\n",
    "    for i in range(D['misfit'].shape[0]):\n",
    "       \n",
    "        misfits = D['misfit'][i]\n",
    "        ax4.plot(sample, misfits/D['ndata'])\n",
    "\n",
    "    ax4.plot([1, D['nsamples']], [1,1], 'k')\n",
    "    ax4.plot([D['burnin'], D['burnin']],[0.1,1e4], 'k')\n",
    "    ax4.set_xlim([1, D['nsamples']])\n",
    "    ax4.set_ylim(0.1, 1e4)\n",
    "\n",
    "    ax4.set_xscale('log')\n",
    "    ax4.set_yscale('log')\n",
    "\n",
    "    ax4.set_xlabel(\"sample #\")\n",
    "    ax4.set_ylabel(\"Normalised misfit\")\n",
    "    \n",
    "    # Ax 5\n",
    "    #res1 = plot_utils.plot_single_line(ax5, gridded_vars[line],\n",
    "    #                                   'data_residual', panel_kwargs[0])\n",
    "\n",
    "    #ax5.set_title('LCI conductivity section - ' + str(line))\n",
    "    \n",
    "    # Ax 6\n",
    "\n",
    "    #im2 = plot_utils.plot_grid(ax6, gridded_vars[line], 'conductivity',\n",
    "    #                           panel_kwargs[1])\n",
    "\n",
    "    #ax6.plot([dist, dist], [-500, 500], 'pink')\n",
    "    #ax6.set_xlabel(\"Distance along line (m)\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Ax7\n",
    "    \n",
    "    #ax7.imshow(np.log10(cond[9]), extent = [cond_dataset.bounds[0],\n",
    "    #                              cond_dataset.bounds[2],\n",
    "    #                              cond_dataset.bounds[1], \n",
    "    #                              cond_dataset.bounds[3]],\n",
    "    #          cmap = 'jet',\n",
    "    #          vmin = np.log10(panel_kwargs[1]['vmin']*1000.),\n",
    "    #          vmax = np.log10(panel_kwargs[1]['vmax']*1000.))\n",
    "    \n",
    "    #ax7.set_xlim(D['easting'] - 10000., D['easting'] + 10000.)\n",
    "    #ax7.set_ylim(D['northing'] - 10000., D['northing'] + 10000.)\n",
    "    #ax7.plot(D['easting'],D['northing'],  'x', c = 'k')\n",
    "    \n",
    "    #p1 = [gridded_vars[line]['easting'][0], gridded_vars[line]['easting'][-1]]\n",
    "    #p2 = [gridded_vars[line]['northing'][0], gridded_vars[line]['northing'][-1]]\n",
    "    #ax7.plot(p1, p2, 'k', linewidth = 0.5)\n",
    "    #ax7.set_title('LCI depth slice 61.8-71.6 mBGL', fontsize=10)\n",
    "    #ax7.tick_params(axis='both', which='major', labelsize=8)\n",
    "    #ax7.tick_params(axis='both', which='minor', labelsize=8)\n",
    "    \n",
    "    # cbar axes\n",
    "    cb1 = fig.colorbar(im, cax=cbar_ax1, orientation='horizontal')\n",
    "    cb1.set_label('probabilitiy', fontsize=10)\n",
    "    \n",
    "        \n",
    "    #cb2 = fig.colorbar(im2, cax=cbar_ax2, orientation='vertical')\n",
    "    \n",
    "    #cb2.ax.set_yticklabels([round(10 ** x, 4) for x in cb2.get_ticks()])\n",
    "    #cb2.set_label('conductivity (S/m)', fontsize=10)\n",
    "    \n",
    "    cb3 =  fig.colorbar(im3, cax=cbar_ax3, orientation='vertical')\n",
    "    cb3.set_label('surface elevation mAHD')\n",
    "    \n",
    "    #ax5.set_xlim(dist - 5000.,\n",
    "    #             dist + 5000.)\n",
    "    ax6.set_xlim(dist - 5000., \n",
    "                 dist + 5000.)\n",
    "\n",
    "    ax_array = np.array([ax1, ax2, ax3, ax4, ax5, ax6, ax7])\n",
    "    \n",
    "    return fig, ax_array   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garjmcmctdem",
   "language": "python",
   "name": "garjmcmctdem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
